{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add model 3, which is keeping the number of producers and also the number of  movies|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from collections import Counter, defaultdict\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import factorial\n",
    "from scipy import stats\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy.stats import ks_2samp\n",
    "from operator import itemgetter\n",
    "\n",
    "src_dir = os.path.abspath(os.path.join(os.pardir, os.pardir,'src'))\n",
    "sys.path[0] = src_dir\n",
    "from parser.support import ROLES, CREDITS\n",
    "from parser.my_mongo_db_login import DB_LOGIN_INFO\n",
    "import parser.support as support\n",
    "import network.shift_graph_maker as sgm\n",
    "import network.network_generator as net_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded IMDb movies producing_gender_percentage\n",
      "Got all_movies\n"
     ]
    }
   ],
   "source": [
    "movie_producer_df = net_gen.open_movie_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building synthetic networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* fixed values\n",
    "    * number of movies per year\n",
    "    * number of producers per year\n",
    "\n",
    "* variables\n",
    "    * number of people per team - producer_num_list *\n",
    "    * number of movies per producer - occurence_list *\n",
    "    * size of gaps - gap_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlistyfied_producer_df = net_gen.unlistify(movie_producer_df, 'producers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of movies per producer of the 90s\n",
    "unlistyfied_producer_df['producer_id'] = unlistyfied_producer_df.producers.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_per_producer = unlistyfied_producer_df.groupby('producer_id').count()['_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3\n",
    "\n",
    "fixed number of movies, fixed number of producers\n",
    "given number of movies per producer\n",
    "given size of gaps per producer/movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3- 0\n",
    "\n",
    "fixed number of movies, fixed number of producers\n",
    "\n",
    "team size round down/up of the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list = net_gen.bootstrap(movies_per_producer, len(movies_per_producer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_producers = len(list(set([i[0] for i in unlistyfied_producer_df.producers.tolist()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = support.get_staff_df('producers')[['_id', 'female_count', 'first_movie', 'last_movie', 'gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "females = sgm.generate_gender_seeds(gender_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1064"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_producer_list = [i[0] for sublist in movie_producer_df.producers.tolist() for i in sublist]\n",
    "seeds = [i for i in females if i in original_producer_list]\n",
    "len(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = support.get_staff_df('producers')[['_id', 'female_count', 'first_movie', 'last_movie', 'gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlistyfied_producer_df['gender'] = unlistyfied_producer_df.apply(net_gen.assign_gender, args=(gender_df,), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_per_producer_gender = {}\n",
    "for g, g_df in unlistyfied_producer_df.groupby('gender'):\n",
    "    movies_per_producer = g_df.groupby('producer_id').count()['_id'].tolist()\n",
    "    movie_per_producer_gender[g] = movies_per_producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "nm0005544\n",
      "[3. 0. 1.]\n",
      "[0.02380952 0.83333333 0.14285714]\n",
      "43\n",
      "nm0918424\n",
      "[3. 0. 1.]\n",
      "[0.02380952 0.83333333 0.14285714]\n"
     ]
    }
   ],
   "source": [
    "movies = []\n",
    "for p, group in unlistyfied_producer_df.groupby('producer_id'):\n",
    "    group_sorted = group.sort_values('year')\n",
    "    diff = group_sorted.year.diff().values\n",
    "    if len(group_sorted) > 40:\n",
    "        print(len(group_sorted))\n",
    "        print(p)\n",
    "#         print(group_sorted.year.tolist())\n",
    "        diff_ratio = Counter(diff[~np.isnan(diff)])\n",
    "        diffs, occur = zip(*diff_ratio.items())\n",
    "        diffs = np.array(diffs)\n",
    "        occur = np.array(occur)\n",
    "        print(diffs)\n",
    "        print(occur/sum(occur))\n",
    "        movies.append(group_sorted.producers.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_dict = net_gen.get_gaps_gender(unlistyfied_producer_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generate movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_producers_per_year = {}\n",
    "for year, df in unlistyfied_producer_df.groupby('year'):\n",
    "    producers = list(set([i[0] for i in df.producers.tolist()]))\n",
    "    number_of_producers_per_year[year] = len(producers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterate years to produce team numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/staff/junelee/miniconda3/envs/movie_network/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/staff/junelee/miniconda3/envs/movie_network/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/staff/junelee/miniconda3/envs/movie_network/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/staff/junelee/miniconda3/envs/movie_network/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/staff/junelee/miniconda3/envs/movie_network/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/staff/junelee/miniconda3/envs/movie_network/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate movies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/staff/junelee/miniconda3/envs/movie_network/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/staff/junelee/miniconda3/envs/movie_network/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/staff/junelee/miniconda3/envs/movie_network/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/staff/junelee/miniconda3/envs/movie_network/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#generate new producers every round\n",
    "generated_producers = net_gen.generate_producers(total_num_producers)\n",
    "generated_producers_dict = {}\n",
    "generated_producers_dict['female'] = generated_producers[:len(seeds)]\n",
    "generated_producers_dict['male'] = generated_producers[len(seeds):]\n",
    "total_movie_frame = movie_producer_df[['_id', 'producers', 'year', 'producer_num']].copy(deep=True)\n",
    "\n",
    "print('iterate years to produce team numbers')\n",
    "for year, df in total_movie_frame.groupby('year'):\n",
    "    num_producers = number_of_producers_per_year[year] #duplicate producers are already dropped\n",
    "    mean_size = np.mean(df.producer_num.tolist())\n",
    "    mean_ceil = np.ceil(mean_size)\n",
    "    mean_floor = np.floor(mean_size)\n",
    "    #fix the team size to its mean\n",
    "    df['producer_num'] = df.producer_num.apply(net_gen.team_size, args=(mean_ceil, mean_floor))\n",
    "    total_movie_frame['producer_num'].update(df.producer_num)\n",
    "total_movie_frame['producers'] = [[]]*len(total_movie_frame)\n",
    "print('generate movies')\n",
    "total_num_teams = total_movie_frame.producer_num.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate movies\n",
    "movie_dict = net_gen.generate_movie_num(total_num_teams, generated_producers_dict, movie_per_producer_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign gaps by gender\n",
    "movie_dict_per_producer, gap_dict_per_producer = net_gen.assign_gaps(movie_dict, gap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribute movies\n",
    "def distribute_movies(df, gap_dict_per_producer):\n",
    "    \"\"\"\n",
    "    Distribute movies according to the gap dist\n",
    "    Input:\n",
    "        df - dataframe for movies\n",
    "        gap_dict_per_producer - dictionary of gaps per producer\n",
    "    Output:\n",
    "        df - dataframe for movies now filled with producers\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy(deep=True)\n",
    "    sorted_gap_dict_per_producer = sorted(gap_dict_per_producer.items(), key=lambda kv: (sum(kv[1]), len(kv[1])), reverse=True)\n",
    "    producers = [p[0] for p in sorted_gap_dict_per_producer]\n",
    "\n",
    "    for p in producers:\n",
    "        gaps = gap_dict_per_producer[p]\n",
    "        shuffle(gaps)\n",
    "        first_movie = find_first_available_movie(df, sum(gaps))\n",
    "        available_movies = find_unfilled_movies(df)\n",
    "        # when is the producer's first active year\n",
    "        start_year = df[df._id == first_movie].year.values[0]\n",
    "        # find the years that the producer made movie\n",
    "        working_years = calculate_years(start_year, gaps)\n",
    "        chosen_movies = choose_movies(available_movies, working_years)\n",
    "        df = add_producers(df, p, chosen_movies)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_producers(df, p, movie_list):\n",
    "    \"\"\"\n",
    "    Append producer p to the producer list in df for the movie list\n",
    "    Input:\n",
    "        df - dataframe of the movies and producers\n",
    "        p - producer\n",
    "        movie_list - list of the movies that producer participated in\n",
    "    Output:\n",
    "        df - dataframe with the appended producer\n",
    "    \"\"\"\n",
    "    mask = df['_id'].isin(movie_list)\n",
    "    df_valid = df[mask]\n",
    "    df.loc[mask, 'producers'] += [p]\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_available_movie(df, N):\n",
    "    \"\"\"\n",
    "    get the first movie to start\n",
    "    \"\"\"\n",
    "    # find movies that are not filled with producers\n",
    "    df['availability'] = df.producers.apply(lambda x: len(x))\n",
    "    df_available = df[df.availability < df.producer_num]\n",
    "    # find movies that has the possibe years considering the sum of gaps N\n",
    "    last_year = df.iloc[-1].year\n",
    "    possible_year = last_year - N\n",
    "    df_available = df_available[df_available.year <= possible_year]\n",
    "    available_movie = np.random.choice(df_available._id.tolist())\n",
    "    return available_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_years(start_year, gaps):\n",
    "    \"\"\"\n",
    "    producers active year\n",
    "    \"\"\"\n",
    "    years = [start_year]\n",
    "    for g in gaps:\n",
    "        years.append(years[-1]+g)\n",
    "    return years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unfilled_movies(df):\n",
    "    df['availability'] = df.producers.apply(lambda x: len(x))\n",
    "    df_available = df[df.availability < df.producer_num]\n",
    "    available_movies = df_available.groupby('year')['_id'].apply(list).to_dict()\n",
    "    return available_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_movies(available_movies, working_years):\n",
    "    \"\"\"\n",
    "    available_movies - {year:[list of movies]}\n",
    "    workign_years - years that prodcer produced movie\n",
    "    \"\"\"\n",
    "    participating_movies = []\n",
    "    for key, values in Counter(working_years).items():\n",
    "        participating_movies.extend(np.random.choice(available_movies[key], values, replace=False))\n",
    "    return participating_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_producer(row, p, movies):\n",
    "    if row._id in movies:\n",
    "        row.producers.append(p)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_movie_frame = distribute_movies(total_movie_frame, gap_dict_per_producer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>producers</th>\n",
       "      <th>year</th>\n",
       "      <th>producer_num</th>\n",
       "      <th>availability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22884</th>\n",
       "      <td>tt0099622</td>\n",
       "      <td>RR501988</td>\n",
       "      <td>1990</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22884</th>\n",
       "      <td>tt0099622</td>\n",
       "      <td>RD702968</td>\n",
       "      <td>1990</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22884</th>\n",
       "      <td>tt0099622</td>\n",
       "      <td>AO164304</td>\n",
       "      <td>1990</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22884</th>\n",
       "      <td>tt0099622</td>\n",
       "      <td>CT940398</td>\n",
       "      <td>1990</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22502</th>\n",
       "      <td>tt0100822</td>\n",
       "      <td>JK358376</td>\n",
       "      <td>1990</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             _id producers  year  producer_num  availability\n",
       "22884  tt0099622  RR501988  1990             4             4\n",
       "22884  tt0099622  RD702968  1990             4             4\n",
       "22884  tt0099622  AO164304  1990             4             4\n",
       "22884  tt0099622  CT940398  1990             4             4\n",
       "22502  tt0100822  JK358376  1990             5             5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlistyfied_result_df = net_gen.unlistify(final_movie_frame, 'producers')\n",
    "unlistyfied_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if distributions are correct\n",
    "movies_data = list(unlistyfied_producer_df.groupby('producer_id').count()['_id'].values)\n",
    "movies_result = list(unlistyfied_result_df.groupby('producers').count()['_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.006773185133726933, pvalue=0.9993698539629257)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "ks_2samp(movies_data, movies_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gap_data = net_gen.get_gaps(unlistyfied_producer_df)\n",
    "gap_result = net_gen.get_gaps(unlistyfied_result_df, 'producers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.08412491123353827, pvalue=7.714148762419836e-16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_2samp(gap_data, gap_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distances(real_data, gen_data):\n",
    "    \"\"\"\n",
    "    Find the distance between realData and genData for each data point\n",
    "    input:\n",
    "        realData - list or numpy array of real Data\n",
    "        genData - list or numpy array of genearted Data\n",
    "    output:\n",
    "        dfDistance - dataframe with data points as index, cdf of real data, gen data and distance between each data point\n",
    "    \"\"\"\n",
    "    data1, data2 = map(np.asarray, (real_data, gen_data))\n",
    "    n1 = len(data1)\n",
    "    n2 = len(data2)\n",
    "    data1 = np.sort(data1)\n",
    "    data2 = np.sort(data2)\n",
    "    data_all = np.concatenate([data1, data2])\n",
    "    cdf1 = np.searchsorted(data1, data_all, side='right')/(1.0*n1)\n",
    "    cdf2 = (np.searchsorted(data2, data_all, side='right'))/(1.0*n2)\n",
    "    d = cdf1 - cdf2\n",
    "    distance_array = np.array([data_all, cdf1, cdf2, d]).T\n",
    "    df_distance = pd.DataFrame(distance_array, columns =['data_all', 'real', 'gen', 'distances'])\n",
    "    df_distance = df_distance.drop_duplicates()\n",
    "    df_distance = df_distance.set_index('data_all')\n",
    "    return df_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_distance(df_distance):\n",
    "    \"\"\"\n",
    "    Find the maximum distance between the data points and the proportion of data\n",
    "    Input\n",
    "        df_distance - DataFrame of cdf of the original data, generated data and distance between the data frame\n",
    "    Output\n",
    "        maxPoint - float, data point where the maximum distance happens\n",
    "        maxDistance - float, the difference between two data at maxPoint\n",
    "    \"\"\"\n",
    "    df_max_dist = df_distance.reindex(df_distance.distances.abs().sort_values().index)\n",
    "    df_max_dist_row = df_max_dist.iloc[-1]\n",
    "    max_point = df_max_dist_row.name\n",
    "    max_distance = df_max_dist_row.distances\n",
    "    return max_point, max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distance = find_distances(gap_data, gap_result)\n",
    "max_p, max_d = find_max_distance(df_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_distance_gaps(df_producers, max_p):\n",
    "    \"\"\"\n",
    "    Find the shifts with the max distant gaps\n",
    "    Input:\n",
    "        df_producers - DataFrame of unlistified producers\n",
    "        max_p - float, data point where the maximum distance happens\n",
    "    Output:\n",
    "        df_match - DataFrame with  matching gaps\n",
    "    \"\"\"\n",
    "    df_producers = unlistyfied_result_df.copy(deep=True)\n",
    "    df_match = pd.DataFrame(columns=['_id', 'producers', 'year', 'gaps'])\n",
    "    producers = df_producers.producers.unique().tolist()\n",
    "    for p, df_select in df_producers.groupby('producers'):\n",
    "        df_select = df_select.sort_values('year')\n",
    "        df_select['gaps'] = df_select.year.diff()\n",
    "        df_select = df_select.dropna()\n",
    "        df_select = df_select[df_select['gaps']==max_p]\n",
    "        if (df_select.empty) == False:\n",
    "            df_match = df_match.append(df_select[['_id', 'producers', 'year', 'gaps']])\n",
    "    return df_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match = find_max_distance_gaps(unlistyfied_result_df, max_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_area(shift_gap, shift_gap_gen):\n",
    "    \"\"\"\n",
    "    get the area between the two probabilities\n",
    "    \"\"\"\n",
    "    df_distance = shuffler.find_distances(shift_gap, shift_gap_gen)\n",
    "    area = df_distance.Distances.abs().sum()\n",
    "\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceptance_probability(area, area_new, temp):\n",
    "    \"\"\"\n",
    "    Are we going to accept the new state?\n",
    "    \"\"\"\n",
    "    k = 0.1\n",
    "    ap = exp((area-area_new)/(k*temp))\n",
    "    return ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(df_producers, gap_data, temp = 1):\n",
    "    \"\"\"\n",
    "    Using simmulated annealing as the shuffle parameter. \n",
    "    note: the p value is not significant, but can find the minimum area between teh two probabilities. \n",
    "    \"\"\"\n",
    "    col_name = 'producers'\n",
    "    df_gen = net_gen.unlistify(df_producers.copy(deep=True))\n",
    "    df_original = net_gen.unlistify(df_producers.copy(deep=True))\n",
    "    alpha = 0.5\n",
    "    pvalue_old = 0\n",
    "    shuf = 3 #number of times to shuffle -> choosing the next 'neighbor'\n",
    "    # counter = 1 #every time counter hits %10 == 0, s is decreased by 1\n",
    "\n",
    "    gap_gen = net_gen.get_gaps(df_gen, col_name)\n",
    "    area = get_area(gap_data, gap_gen)\n",
    "    counter = 0\n",
    "    while temp > 0.05:\n",
    "\"\"\"\"\"\"        for s in range(shuf):\n",
    "\"\"\"\"\"\"            df_gen_new = shuffler.shuffle(df_gen, gap_data, gap_gen)\n",
    "        #get the new area\n",
    "        gap_gen_new = net_gen.get_gaps(df_gen_new, col_name)\n",
    "        area_new = get_area(gap_data, gap_gen_new)\n",
    "        #Accept if area_new < area\n",
    "        if area_new < area:\n",
    "            # print('\\t New area smaller than old')\n",
    "            df_gen = df_gen_new\n",
    "            area = copy(area_new)\n",
    "            temp = temp*alpha\n",
    "        #if new area is bigger than old area, do probability acceptance\n",
    "        else:\n",
    "            # print('\\t New area larger than old')\n",
    "            ap = acceptance_probability(area, area_new, temp)\n",
    "            p = random()\n",
    "            if ap > p:\n",
    "                # print('\\t\\t Accepted, ap>p {:.3f}'.format(ap))\n",
    "                # print('\\t ***Accept True***')\n",
    "                df_gen = df_physician_new.copy(deep=True)\n",
    "                area = area_new\n",
    "            # else:\n",
    "            #     print('\\t\\t Not accepted')\n",
    "#         if area <= 0.18:\n",
    "#             stop_count = counter\n",
    "#             print(stop_count, temp, area)\n",
    "#             temp = 0.01\n",
    "        if temp < 0.09:\n",
    "            print(temp, area)\n",
    "        counter += 1\n",
    "    gap_gen = net_gen.get_gaps(df_gen, col_name)\n",
    "    D, pvalue = ks_2samp(gap_data, gap_gen)\n",
    "    print('\\t\\t P value: {:.3f}, counter {}'.format(pvalue, counter))    \n",
    "\n",
    "    return df_producers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1786., 1760.,  853.,  381.,  150.,   58.,   24.,   21.,    3.]),\n",
       " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " <a list of 9 Patch objects>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "bins = np.arange(0, 10,1)\n",
    "ax.hist(gap_data, bins=bins, color='red', alpha=0.3)\n",
    "ax.hist(gap_result, bins=bins, color='blue', alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make shuffle source file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(df, gap_data, gap_gen):\n",
    "    \"\"\"\n",
    "    shuffle according to the distance\n",
    "    Input:\n",
    "        df - unlistyfied producer dataframe\n",
    "        gap_data - gap list from data\n",
    "        gap_gen - gap list from generated data\n",
    "    Output: \n",
    "        df_new - unlistyfied producer dataframe\n",
    "    \"\"\"\n",
    "    df = df.copy(deep=True)\n",
    "    df_distance = find_distances(gap_data, gap_gen)\n",
    "    maxP, maxD = find_max_distance(df_distance)\n",
    "    if maxD < 0:\n",
    "        df_new = shuffle_negative(df, maxP)\n",
    "    if maxD >= 0:\n",
    "        df_new = shuffle_positive(df, maxP)\n",
    "    return df_physician_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'tt0099622'\n",
    "p = 'RR501988'\n",
    "unlistyfied_result_df[unlistyfied_result_df['_id'] == m].producers.tolist()\n",
    "df = unlistyfied_result_df.copy(deep=True)\n",
    "maxP = max_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_negative(df, maxP):\n",
    "    \"\"\"\n",
    "    Shuffle the cases when the max distance is negative\n",
    "    Probability of the gap for generated data > real data\n",
    "    Input:\n",
    "        df - unlistyfied producer schedules\n",
    "        maxP - float, the point of the maximum distance between to data\n",
    "    Output:\n",
    "        df_new - DataFrame shuffled\n",
    "    \"\"\"\n",
    "    df_new = df.copy(deep=True)\n",
    "\n",
    "    df_match = find_max_distance_gaps(df_new, maxP)\n",
    "\n",
    "    if len(df_match) >= 2:\n",
    "        # print('From samples')\n",
    "        movie1, movie2, producer1, producer2, p_list1, p_list2 = pick_producers(df_match)\n",
    "        counter = 0\n",
    "        while (producer1 in p_list2) or (producer2 in p_list1): #if producer1 and producer2's movies overlap\n",
    "            # print('\\t Still choosing from the samples', samples)\n",
    "            movie1, movie2, producer1, producer2, p_list1, p_list2 = pick_producers(df_match)\n",
    "            counter += 1\n",
    "            if counter > 100: #if while goes too long, break\n",
    "                # print('\\t Switching to random')\n",
    "                movie1, movie2, producer1, producer2, p_list1, p_list2 = pick_producers(df_new)\n",
    "    else: #if the doctors in df_atch is less than 2 pick random doctors\n",
    "        # print('Random')\n",
    "        movie1, movie2, producer1, producer2, p_list1, p_list2 = pick_producers(df_new)\n",
    "\n",
    "    #swap\n",
    "    df_new.loc[(df_new._id == movie1) & (df_new.producers == producer1), 'producers'] = producer2\n",
    "    df_new.loc[(df_new._id == movie2) & (df_new.producers == producer2), 'producers'] = producer1\n",
    "\n",
    "    return df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_producers(df_match, n=2):\n",
    "    \"\"\"\n",
    "    pick producers to switch, condition - cannot be in the same movie\n",
    "    \"\"\"\n",
    "    samples = df_match.sample(n=n)\n",
    "    print(samples)\n",
    "    #choose random shifts with max distance gap\n",
    "    movie1, movie2 = samples._id\n",
    "    producer1, producer2 = samples.producers\n",
    "    p_list1 = df_new['producers'][df['_id'] == movie1].tolist()\n",
    "    p_list2 = df_new['producers'][df['_id'] == movie2].tolist()\n",
    "    return movie1, movie2, producer1, producer2, p_list1, p_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_positive(dfPhysician, maxP, docType, shift_type):\n",
    "    \"\"\"\n",
    "    Shuffle the cases when the max distance is positive\n",
    "    Probability of the gap for generated data < real data\n",
    "    Input:\n",
    "        dfPhysician - DataFrame of Physician schedule\n",
    "        maxP - float, the point of the maximum distance between to data\n",
    "        docType - string 'Fellow', 'Attending'\n",
    "    Output:\n",
    "        dfPhysicianNew - DataFrame shuffled\n",
    "    \"\"\"\n",
    "    dfPhysicianNew = copy(dfPhysician)\n",
    "    if shift_type == 'week':\n",
    "        dfPhysicianNew = dfPhysicianNew[dfPhysicianNew['Days'] == 5]\n",
    "    if shift_type == 'wkend':\n",
    "        dfPhysicianNew = dfPhysicianNew[dfPhysicianNew['Days'] == 2]\n",
    "\n",
    "    dfMatch = find_max_distance_gaps(dfPhysicianNew,maxP,docType)\n",
    "    zeroShifts = []\n",
    "    #Pick the first shifts that match (which is excluded in find_max_distance_gaps)\n",
    "    for doc in dfMatch[docType].unique().tolist():\n",
    "        firstIndex = dfMatch[dfMatch[docType]==doc].index.tolist()[0]\n",
    "        firstDate = dfMatch['Date'][firstIndex]\n",
    "        zeroShift = dfPhysicianNew[(dfPhysicianNew['Date'] == firstDate - pd.Timedelta(weeks=maxP+1)) \n",
    "                                   & (dfPhysicianNew[docType]==doc)].index.values.tolist()\n",
    "        zeroShifts += zeroShift \n",
    "\n",
    "    excluded = dfMatch.index.tolist() + zeroShifts\n",
    "    samples = [i for i in dfPhysicianNew.index.tolist() if i not in excluded]\n",
    "    shiftNorm = random.choice(samples)\n",
    "    docTarget = copy(dfPhysicianNew[docType][shiftNorm]) #doctor we are targeting to change\n",
    "    date1 = copy(dfPhysicianNew['Date'][shiftNorm]) + pd.Timedelta(weeks=maxP+1)\n",
    "    doctors1 = dfPhysicianNew[docType][dfPhysicianNew['Date']==date1].values.tolist() #doctors in the target date\n",
    "    #Target doctors' all shifts that is not the shiftNorm\n",
    "    #Choose Only if the shifts don't have the maxP\n",
    "    docShifts = [s for s in dfPhysicianNew[dfPhysicianNew[docType]==docTarget].index.tolist() if s != shiftNorm and s in samples]\n",
    "    random.shuffle(docShifts)\n",
    "    for i in docShifts:\n",
    "        date2 = dfPhysicianNew['Date'][i]\n",
    "        doctors2 = dfPhysicianNew[docType][dfPhysicianNew['Date'] == date2].values.tolist()\n",
    "        overlappingDocs = list(set(doctors1) - set(doctors2))\n",
    "        if overlappingDocs:\n",
    "            #Only if the shifts don't have have the maxP\n",
    "            uniqueShifts = dfPhysicianNew[(dfPhysicianNew['Date'] == date1) & dfPhysicianNew.index.isin(samples)].index.tolist()\n",
    "            if uniqueShifts:\n",
    "                shift1 = random.choice(uniqueShifts)\n",
    "                docChange = dfPhysicianNew[docType][shift1]\n",
    "                shift1 = dfPhysicianNew[(dfPhysicianNew[docType] == docChange) & (dfPhysicianNew['Date'] == date1)].index.tolist()[0] \n",
    "                shift2 = dfPhysicianNew[(dfPhysicianNew[docType] == docTarget) & (dfPhysicianNew['Date'] == date2)].index.tolist()[0]\n",
    "                dfPhysicianNew.loc[shift1, docType] = docTarget\n",
    "                dfPhysicianNew.loc[shift2, docType] = docChange\n",
    "                break\n",
    "    \n",
    "    return dfPhysicianNew\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataframe with the exact team sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/projects/movie-network/data/synthetic_data/model_3_0/'\n",
    "gender_dir = '/home/projects/movie-network/data/synthetic_data/genders/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_schedules = 1\n",
    "version_list = net_gen.make_version(num_schedules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in sorted(gap_dict_per_producer.items(),key=lambda i:(sum(i[1]), len(i[1])),reverse=True):\n",
    "    print(key, value, sum(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_movie_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shift_dist = []\n",
    "# for v in range(num_schedules):\n",
    "\n",
    "\n",
    "#generate new producers every round\n",
    "generated_producers = net_gen.generate_producers(total_num_producers)\n",
    "generated_producers_dict = {}\n",
    "generated_producers_dict['female'] = generated_producers[:len(seeds)]\n",
    "generated_producers_dict['male'] = generated_producers[len(seeds):]\n",
    "total_movie_frame = movie_producer_df[['_id', 'producers', 'year', 'producer_num']].copy(deep=True)\n",
    "print('iterate years')\n",
    "for year, df in total_movie_frame.groupby('year'):\n",
    "    num_producers = number_of_producers_per_year[year] #duplicate producers are already dropped\n",
    "    mean_size = np.mean(df.producer_num.tolist())\n",
    "    mean_ceil = np.ceil(mean_size)\n",
    "    mean_floor = np.floor(mean_size)\n",
    "    #fix the team size to its mean\n",
    "    df['producer_num'] = df.producer_num.apply(team_size, args=(mean_ceil, mean_floor))\n",
    "    total_movie_frame['producer_num'].update(df.producer_num)\n",
    "total_movie_frame['producers'] = np.nan\n",
    "print('generate movies')\n",
    "total_num_teams = total_movie_frame.producer_num.sum()\n",
    "dict_movies = generate_movie_num(total_num_teams, generated_producers_dict, movie_per_producer_gender)\n",
    "shift_dist.append(list(dict_movies.values()))\n",
    "print('distribute movies')\n",
    "\n",
    "\n",
    "    \n",
    "for i, row in total_movie_frame.iterrows():\n",
    "    producers, occurence = zip(*dict_movies.items())\n",
    "    producers = np.array(producers)\n",
    "    occurence = np.array(occurence)\n",
    "    size = row.producer_num\n",
    "    team = np.random.choice(producers, size, replace=False, p=occurence/sum(occurence))\n",
    "    #assign list to cell\n",
    "    total_movie_frame['producers'] = total_movie_frame['producers'].astype(object)\n",
    "    total_movie_frame.at[i, 'producers'] = team\n",
    "    for p in team:\n",
    "        dict_movies[p] -= 1\n",
    "        if dict_movies[p] == 0:\n",
    "            del dict_movies[p]\n",
    "            \n",
    "            \n",
    "            \n",
    "#     total_movie_frame.to_json(os.path.join(data_dir, 'movies_3_0_{}.json'.format(version_list[v])), orient='split')\n",
    "#     #save gender\n",
    "#     generated_gender_df = pd.DataFrame(columns=['producer_id', 'gender'])\n",
    "#     for g, producers in generated_producers_dict.items():\n",
    "#         genders = [g for ii in producers]\n",
    "#         appending_df = pd.DataFrame({'producer_id': producers, 'gender': genders})\n",
    "#         generated_gender_df = generated_gender_df.append(appending_df)\n",
    "#     generated_gender_df.to_json(os.path.join(gender_dir, 'movies_3_0', 'version_{}.json'.format(version_list[v])), orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_list = list(set([i for sublist in total_movie_frame.producers.tolist() for i in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in shift_dist:\n",
    "    print(ks_2samp(l, movie_per_producer_gender['male']+movie_per_producer_gender['female']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2-1\n",
    "\n",
    "fixed number of movies, fixed number of producers\n",
    "\n",
    "team size sampled from the real schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in producers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_schedules = 10\n",
    "\n",
    "version_list = []\n",
    "while len(version_list) < num_schedules:\n",
    "    ver = make_version()\n",
    "    if ver not in version_list:\n",
    "        version_list.append(ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "original_file_list = [join(original_dir, f) for f in listdir(original_dir) \n",
    "                       if isfile(join(original_dir, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat over multiple years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_producer_df[['_id', 'producers', 'year', 'producer_num']].copy(deep=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/projects/movie-network/data/synthetic_data/model_2_1/'\n",
    "\n",
    "shift_dist = []\n",
    "for v in range(num_schedules):\n",
    "    #generate new producers every round\n",
    "    generated_producers = net_gen.generate_producers(total_num_producers)\n",
    "    generated_producers_dict = {}\n",
    "    generated_producers_dict['female'] = generated_producers[:len(seeds)]\n",
    "    generated_producers_dict['male'] = generated_producers[len(seeds):]\n",
    "    total_movie_frame = movie_producer_df[['_id', 'producers', 'year', 'producer_num']].copy(deep=True)\n",
    "    total_movie_frame['producers'] = np.nan\n",
    "    print('generate movies')\n",
    "    total_num_teams = total_movie_frame.producer_num.sum()\n",
    "    dict_movies = generate_movie_num(total_num_teams, generated_producers_dict, movie_per_producer_gender)\n",
    "    shift_dist.append(list(dict_movies.values()))\n",
    "    print('distribute movies')\n",
    "    for i, row in total_movie_frame.iterrows():\n",
    "        producers, occurence = zip(*dict_movies.items())\n",
    "        producers = np.array(producers)\n",
    "        occurence = np.array(occurence)\n",
    "        size = row.producer_num\n",
    "        team = np.random.choice(producers, size, replace=False, p=occurence/sum(occurence))\n",
    "        total_movie_frame['producers'] = total_movie_frame['producers'].astype(object)\n",
    "        total_movie_frame.at[i, 'producers'] = team\n",
    "        for p in team:\n",
    "            dict_movies[p] -= 1\n",
    "            if dict_movies[p] == 0:\n",
    "                del dict_movies[p]\n",
    "    total_movie_frame.to_json(os.path.join(data_dir, 'movies_2_1_{}.json'.format(version_list[v])), orient='split')\n",
    "    #save gender\n",
    "    generated_gender_df = pd.DataFrame(columns=['producer_id', 'gender'])\n",
    "    for g, producers in generated_producers_dict.items():\n",
    "        genders = [g for ii in producers]\n",
    "        appending_df = pd.DataFrame({'producer_id': producers, 'gender': genders})\n",
    "        generated_gender_df = generated_gender_df.append(appending_df)\n",
    "    generated_gender_df.to_json(os.path.join(gender_dir, 'movies_2_1', 'version_{}.json'.format(version_list[v])), orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in shift_dist:\n",
    "    print(ks_2samp(l, movie_per_producer_gender['male']+movie_per_producer_gender['female']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "\n",
    "Random sampling does not account for all of the producers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import normpath, basename, join, isfile\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_model =  basename(normpath(data_dir))\n",
    "gender_folder = os.path.join('/home/projects/movie-network/data/synthetic_data/genders/', network_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_file = [join(gender_folder, f) for f in listdir(gender_folder) if isfile(join(gender_folder, f)) and ver in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(gender_file) == 1:\n",
    "    gender_file = gender_file[0]\n",
    "else:\n",
    "    raise IndexError('the version has duplicate or it does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gender = pd.read_json(gender_file, orient='split')\n",
    "seeds = df_gender[df_gender.gender=='female'].producer_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import dirname, realpath\n",
    "two_up = dirname(dirname(__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath(os.path.join(data_dir, os.pardir, 'gender'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
